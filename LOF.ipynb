{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfsdVV-PhRGX",
        "outputId": "a6723844-6698-4685-d5d8-aae5f45ad411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8k4vQpGfvde"
      },
      "outputs": [],
      "source": [
        "from operator import index\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from fastai.tabular.all import df_shrink\n",
        "from google.colab import data_table\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# For LOF\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "testing = '/content/drive/MyDrive/Testing/KDDTest+.csv'\n",
        "training = '/content/drive/MyDrive/Testing/KDDTrain+.csv'\n",
        "\n",
        "train = pd.read_csv(training, encoding='utf-8')\n",
        "test = pd.read_csv(testing, encoding='utf-8')\n",
        "\n",
        "train = df_shrink(train, skip=[], obj2cat=True, int2uint=True)\n",
        "test = df_shrink(test, skip=[], obj2cat=True, int2uint=True)\n",
        "\n",
        "feature_type_map = {f: (train.dtypes.loc[f], test.dtypes.loc[f]) for f in train.columns}\n",
        "\n",
        "len(train['class'].cat.categories), len(test['class'].cat.categories)\n",
        "\n",
        "len(train.service.cat.categories), len(test.service.cat.categories)\n",
        "\n",
        "def train_test_category_union(feature):\n",
        "  tcl = len(train[feature].cat.categories)\n",
        "  tcll = len(test[feature].cat.categories)\n",
        "  feature_cat_union = train[feature].cat.categories.union(test[feature].cat.categories)\n",
        "  train[feature] = train[feature].cat.set_categories(feature_cat_union)\n",
        "  test[feature] = test[feature].cat.set_categories(feature_cat_union)\n",
        "\n",
        "cat = list(train.select_dtypes(include='category').columns.values)\n",
        "\n",
        "for f in cat:\n",
        "  train_test_category_union(f)\n",
        "\n",
        "class_data_train = train['class']\n",
        "#one hot encoding on all nominal categories except class\n",
        "test = pd.get_dummies(test, columns=['protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_host_login', 'is_guest_login'])\n",
        "train = pd.get_dummies(train, columns=['protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_host_login', 'is_guest_login'])\n",
        "\n",
        "#label encoding for class column since it is the target variable\n",
        "le = LabelEncoder()\n",
        "train['classification'] = le.fit_transform(train['class'])\n",
        "test['classification'] = le.fit_transform(test['class'])\n",
        "train.drop('class', axis=1, inplace=True)\n",
        "test.drop('class', axis=1, inplace=True)\n",
        "\n",
        "#robust scaling for normalization step\n",
        "robust_scaler1 = RobustScaler()\n",
        "robust_scaler2 = RobustScaler()\n",
        "#data1 = test.values[:, :-1]\n",
        "data1 = test.values[:, :]\n",
        "#data2 = train.values[:, :-1]\n",
        "data2 = train.values[:, :]\n",
        "data1 = robust_scaler1.fit_transform(data1)\n",
        "data2 = robust_scaler2.fit_transform(data2)\n",
        "#converting array back to dataframe\n",
        "test = pd.DataFrame(data1)\n",
        "train = pd.DataFrame(data2)\n",
        "\n",
        "# X_train = train.drop('classification', axis=1)\n",
        "# y_train = train['classification']\n",
        "# X_test = test.drop('classification', axis=1)\n",
        "# y_test = test['classification']\n",
        "\n",
        "\n",
        "# # Standard Scaling for normalization step\n",
        "# standard_scaler1 = StandardScaler()\n",
        "# standard_scaler2 = StandardScaler()\n",
        "\n",
        "# # use all columns (including classification, but we fix that below)\n",
        "# data1 = test.values[:, :]\n",
        "# data2 = train.values[:, :]\n",
        "\n",
        "# # fit on train, transform both\n",
        "# data1 = standard_scaler1.fit_transform(data1)\n",
        "# data2 = standard_scaler2.fit_transform(data2)\n",
        "\n",
        "\n",
        "# # convert back to DataFrame\n",
        "# # test = pd.DataFrame(data1, columns=test.columns)\n",
        "# test = pd.DataFrame(data1)\n",
        "# # train = pd.DataFrame(data2, columns=train.columns)\n",
        "# train = pd.DataFrame(data2)\n",
        "\n",
        "# Preprocessing ends here\n",
        "\n",
        "# print(test[126]).to_string(index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1IrMB0R72Op",
        "outputId": "c9446af4-bd65-4165-b7fa-f18a02a1cf5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7688076650106459\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            " Anomaly (0)       0.88      0.69      0.77     12833\n",
            "  Normal (1)       0.68      0.87      0.76      9711\n",
            "\n",
            "    accuracy                           0.77     22544\n",
            "   macro avg       0.78      0.78      0.77     22544\n",
            "weighted avg       0.79      0.77      0.77     22544\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Separates features and labels\n",
        "X_train = train.drop(train.columns[-1], axis=1)  # all but last col\n",
        "y_train = train[train.columns[-1]]               # last col is classification\n",
        "X_test = test.drop(test.columns[-1], axis=1)\n",
        "y_test = test[test.columns[-1]]\n",
        "\n",
        "# Initialize the LOF\n",
        "lof = LocalOutlierFactor(n_neighbors=3, novelty=True, contamination=0.00522) # 3 / 0.00522 : 0.7688520227111426\n",
        "\n",
        "# Fit on training data\n",
        "lof.fit(X_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = lof.predict(X_test)\n",
        "\n",
        "# LOF outputs: -1 = anomaly, 1 = normal\n",
        "# We need: 0 = anomaly, 1 = normal\n",
        "# Convert predictions\n",
        "y_pred = np.where(y_pred == -1, 0, 1)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"Anomaly (0)\", \"Normal (1)\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDct4VyY9DEO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwEyiyp17cuK"
      },
      "outputs": [],
      "source": [
        "#outliers_train = len(train[train[126]==-1])/float(len(train[train[126]==0]))\n",
        "#outliers_test = len(test[test[126]==0])/float(len(test))\n",
        "#print(outliers_test)\n",
        "#detection_model_test = IsolationForest(n_estimators=356, contamination=0.000001, random_state=60)\n",
        "# estimate = 251\n",
        "# contam = .41450284628489975\n",
        "# samples =4020\n",
        "# state = 94\n",
        "# for i in range(200):\n",
        "#   detection_model = IsolationForest(n_estimators=estimate, contamination=contam, random_state=state, max_samples=samples)\n",
        "#   detection_model.fit(train)\n",
        "#   y_test_pred = detection_model.predict(test)\n",
        "#   y_test_pred[y_test_pred == 1] = 1\n",
        "#   y_test_pred[y_test_pred == -1] = 0\n",
        "#   print(accuracy_score(target_test, y_test_pred))\n",
        "#   #state = state + 1\n",
        "#   #estimate = estimate - 1\n",
        "#   contam = contam - .0000000005000\n",
        "#   #samples = samples + 10\n",
        "# #detection_model.fit(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2gCvkemfjwA"
      },
      "outputs": [],
      "source": [
        "# #plt.figure(figsize=(50,50))\n",
        "# plt.figure()\n",
        "# #plt.ylim(0, 50)\n",
        "# #plt.xlim(0,1000)\n",
        "# plt.scatter(test.iloc[y_test_pred==0,0].values, test.iloc[y_test_pred==0,1].values, c='blue', label='Normal')\n",
        "# plt.scatter(test.iloc[y_test_pred==1,0].values, test.iloc[y_test_pred==1,1].values, c='red', label='Anomaly')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}